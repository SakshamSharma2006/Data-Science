{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RE9HWe2NcmGU"
      },
      "outputs": [],
      "source": [
        "#Open the text file :\n",
        "text_file = open(\"/content/Underneath my outside face.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Read the data :\n",
        "text = text_file.read()"
      ],
      "metadata": {
        "id": "pTLyoKxscvCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Datatype of the data read :\n",
        "print (type(text))\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "hfvAkjXGcygj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print the text :\n",
        "print(text)\n",
        "print(\"\\n\")\n",
        "#Length of the text :\n",
        "print (len(text))"
      ],
      "metadata": {
        "id": "j_rJYaAic1CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import required libraries :\n",
        "import nltk\n",
        "from nltk import sent_tokenize\n",
        "from nltk import word_tokenize\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"popular\")"
      ],
      "metadata": {
        "id": "gKRamVw8c4I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenize the text by sentences :\n",
        "sentences = sent_tokenize(text)\n",
        "#How many sentences are there? :\n",
        "print (len(sentences))\n",
        "#Print the sentences :\n",
        "#print(sentences)\n",
        "sentences"
      ],
      "metadata": {
        "id": "8ylkyxGrc9uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenize the text with words :\n",
        "words = word_tokenize(text)\n",
        "#How many words are there? :\n",
        "print (len(words))\n",
        "print(\"\\n\")\n",
        "#Print words :\n",
        "print (words)"
      ],
      "metadata": {
        "id": "lFnrfh_RdAyk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}